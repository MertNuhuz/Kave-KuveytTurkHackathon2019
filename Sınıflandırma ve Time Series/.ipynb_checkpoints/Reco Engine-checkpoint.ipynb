{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     116
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mertnuhuz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "x\n",
    "def Twitter(username=\"kuveytturk\"):\n",
    "    with open('turkce-stop-words.txt') as file:\n",
    "        stw = file.read()\n",
    "    stw = stw.split()\n",
    "    stw = [s.lower() for s in stw]\n",
    "    stop = stw\n",
    "\n",
    "    #Modellerin İçeri Alınması\n",
    "    kokbul1 = stemmer('turkish')\n",
    "    filename = 'model.sav'\n",
    "    filenamev2 = 'vectorizer.sav'\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    loaded_vectorizer = pickle.load(open(filenamev2, 'rb'))\n",
    "    def preprocessing(text):\n",
    "        text = text.lower()\n",
    "        # get rid of non-alphanumerical characters\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        # get rid of spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "            # Correct mistakes\n",
    "            # and do the stemming\n",
    "        return \" \".join([word for word in kokbul1.stemWords(text.split()) if word not in stop])\n",
    "\n",
    "    def predicting(x):\n",
    "        test_sample = []\n",
    "        for i in range(len(x)):\n",
    "            test_sample.append(preprocessing(x[i]))\n",
    "        sample = loaded_vectorizer.transform(test_sample).toarray()\n",
    "        result = loaded_model.predict(sample)\n",
    "        return result\n",
    "\n",
    "    def Graph(result):\n",
    "        labels = ['Olumsuz', 'Nötr', 'Olumlu']\n",
    "        sizes = [(result == 0).sum(), (result == 1).sum(), (result == 2).sum()]\n",
    "        colors = ['Red', 'gold', 'yellowgreen']\n",
    "        patches, texts = plt.pie(sizes, colors=colors, shadow=True,startangle=90)\n",
    "        plt.legend(patches, labels, loc=\"best\")\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "    def GetTweets(username):\n",
    "        #Twitter API Settings\n",
    "        auth = tweepy.OAuthHandler(\"b31NqruIj0m3D6mzOk4glEfz7\",\"yAku57PMlQ9V6MVxUrrzkGxI4izrwGCzvI8Q5OwPwyFeLCR0oT\")\n",
    "        auth.set_access_token(\"352938901-hH3mCRnw7ir8acB7oFQwfsu9gaboZeu20Hbm2jWi\", \"t2vYixvZemUibVI95QuapcqwEUCITki7xWFK6DjLTvGce\")\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        #Get Tweets\n",
    "        tweets = []\n",
    "        fetched_tweets = api.user_timeline(screen_name = username, count = 100, include_rts = True)\n",
    "\n",
    "        for tweet in fetched_tweets:\n",
    "            tweets.append(preprocessing(tweet.text))\n",
    "\n",
    "        sentiment = {'olumsuz':0, 'notr':1, 'olumlu':2}\n",
    "        sentimentters = {0:'Olumsuz', 1:'Notr', 2:'Olumlu'}\n",
    "        inv_sentiment = {v:k for k, v in sentiment.items()}\n",
    "\n",
    "        result =  predicting(tweets)\n",
    "\n",
    "        sentimentters = {0:'Olumsuz', 1:'Notr', 2:'Olumlu'}\n",
    "        x,y,c = [],[],[]\n",
    "\n",
    "        x = list(pd.DataFrame(result)[0].map(sentimentters).value_counts().values)\n",
    "        y = list(pd.DataFrame(result)[0].map(sentimentters).value_counts().index)\n",
    "        c = pd.DataFrame(x,y,columns=[username]).T\n",
    "        return c\n",
    "    c = GetTweets(username)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025900288779450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcustomer = GetData(\"4025900288779450\")\n",
    "GetGroup(newcustomer,\"4025900288779450\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4025900418055430 - Class 3\n",
    "#4025900213283250 - Class 2\n",
    "#4025900288779450 - Class 0\n",
    "#4025900517881690 - Class 1\n",
    "\n",
    "#Limitler Bazında\n",
    "#Grup 0 Öğrenciler Çünkü Kredi Kartı Limitleri AŞIRI DÜŞÜK\n",
    "#Grup 3 Emekli-Esnaf Limitler Düşük - Orta\n",
    "#Grup 1 Beyaz-Altın Yakalılar Limitler Yüksek\n",
    "#Grup 2 Mavi Yakalılar Çünkü Limitler Orta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "D:\\Anaconda\\lib\\site-packages\\fbprophet\\forecaster.py:353: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  np.linspace(0, hist_size - 1, self.n_changepoints + 1)\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n"
     ]
    }
   ],
   "source": [
    "dataYemek, dataGiyim, dataFatura, dataHizmet, dataAlisveris, dfYemek, dfGiyim, dfFatura, dfHizmet, dfAlisveris = TimeSeries(\"number2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notr</th>\n",
       "      <th>Olumlu</th>\n",
       "      <th>Olumsuz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uzay00</th>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Notr  Olumlu  Olumsuz\n",
       "uzay00    85      10        5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter(\"uzay00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alışveriş'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def EnCokHarcamaYapilanAlan(dataYemek,dataAlisveris, dataFatura, dataGiyim, dataHizmet):\n",
    "    analysisdf = pd.DataFrame({\"Yemek\":dataYemek.Prices.values[-1],\n",
    "                  \"Alışveriş\":dataAlisveris.Prices.values[-1],\n",
    "                  \"Fatura\":dataFatura.Prices.values[-1],\n",
    "                  \"Giyim\":dataGiyim.Prices.values[-1],\n",
    "                  \"Hizmet\":dataHizmet.Prices.values[-1]},index=[0]).iloc[0]\n",
    "    return analysisdf.index[list(analysisdf.values).index(analysisdf.values.max())]\n",
    "\n",
    "EnCokHarcamaYapilanAlan(dataYemek,dataAlisveris, dataFatura, dataGiyim, dataHizmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

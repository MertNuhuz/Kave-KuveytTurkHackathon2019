{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     116
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mertnuhuz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import datetime\n",
    "from random import randint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fbprophet import Prophet\n",
    "import time\n",
    "import tweepy\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "from snowballstemmer import stemmer\n",
    "\n",
    "def groupprediction(x):\n",
    "    kmeans = pickle.load(open('kmeans.sav', 'rb'))\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(1,-1)\n",
    "    return kmeans.predict(x)\n",
    "\n",
    "def GetData(cardnumber):\n",
    "    API_ENDPOINT = \"https://apitest.kuveytturk.com.tr/prep/v1/cards/carddetail\"\n",
    "    headers = {\n",
    "        'Content-Type': \"application/json\",\n",
    "        'Authorization': \"Bearer 5dbe96a0451c334e72b8665811e8ec1348ab72203a70f27d28a0b5ea99e215a3\"\n",
    "        }\n",
    "    # data to be sent to api\n",
    "    data = {\n",
    "      \"request\": {\n",
    "        \"cardnumber\": str(cardnumber)\n",
    "      }\n",
    "    }\n",
    "    data = json.dumps(data)\n",
    "    # sending post request and saving response as response object\n",
    "    r = requests.post(url = API_ENDPOINT, headers = headers,data = data)\n",
    "    pastebin_url = r.text\n",
    "    pastebin_url = pastebin_url[9:-51]\n",
    "    return json.loads(pastebin_url)\n",
    "\n",
    "def test():\n",
    "    if pd.DataFrame.from_dict(json_normalize(newcustomer), orient='columns')[[\"CardProductCode\",\"IsIntermTransactions\"]].values[0][1] == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def labelencoder(newcustomer):\n",
    "    labelencoder = pickle.load(open('labelencoder.sav', 'rb'))\n",
    "    x = [pd.DataFrame.from_dict(json_normalize(newcustomer), orient='columns')[[\"CardProductCode\",\"IsIntermTransactions\"]].values[0][0]]\n",
    "    return labelencoder.transform(x)\n",
    "\n",
    "\n",
    "\n",
    "def GetGroup(newcustomer,cardnumber):\n",
    "    print(cardnumber)\n",
    "    sube = [190, 181,  31,  31,  26,  25,  24,  23,  22,  21]\n",
    "    if cardnumber == \"4025900213283250\":\n",
    "        array = np.array([labelencoder(newcustomer),15,test()])\n",
    "    elif cardnumber == \"4025900288779450\":\n",
    "        array = np.array([labelencoder(newcustomer),114,test()])\n",
    "    elif cardnumber == \"4025900418055430\":\n",
    "        array = np.array([labelencoder(newcustomer),219,test()])\n",
    "    elif cardnumber == \"4025900517881690\":\n",
    "        array = np.array([labelencoder(newcustomer),292,test()])\n",
    "    else:\n",
    "        array = np.array([labelencoder(newcustomer),sube[randint(0,len(sube)-1)],test()])\n",
    "    return groupprediction(array)\n",
    "\n",
    "def dataMonth(data):\n",
    "    data = data.resample(\"M\").sum()\n",
    "    data[\"Date\"] = data.index\n",
    "    data.index = range(0,len(data))\n",
    "    return data\n",
    "\n",
    "def Fitting(df):\n",
    "    my_model = Prophet()\n",
    "    my_model.fit(df)\n",
    "\n",
    "    future_dates = my_model.make_future_dataframe(periods=3, freq=\"M\")\n",
    "    forecast = my_model.predict(future_dates)\n",
    "    \n",
    "    forecastnew = forecast['ds']\n",
    "    forecastnew2 = forecast['yhat']\n",
    "    forecastnew = pd.concat([forecastnew,forecastnew2], axis=1)\n",
    "    forecastnew = forecastnew[len(forecastnew)-3:]\n",
    "    return forecastnew\n",
    "\n",
    "def TimeSeries(datapath):\n",
    "    datax = pd.read_excel(datapath, date_parser=[0])\n",
    "    dataAlisveris = datax[datax.Hizmet == \"Alışveriş\"].copy();dataAlisveris.drop([\"CardNumber\",\"Hizmet\"],axis=1,inplace=True);dataAlisveris.set_index(\"Date\",inplace=True)\n",
    "    dataYemek = datax[datax.Hizmet == \"Yemek\"][[\"Date\",\"Prices\"]].copy();dataYemek.set_index(\"Date\",inplace=True)\n",
    "    dataGiyim = datax[datax.Hizmet == \"Giyim\"][[\"Date\",\"Prices\"]].copy();dataGiyim.set_index(\"Date\",inplace=True)\n",
    "    dataFatura = datax[datax.Hizmet == \"Fatura\"][[\"Date\",\"Prices\"]].copy();dataFatura.set_index(\"Date\",inplace=True)\n",
    "    dataHizmet = datax[datax.Hizmet == \"Hizmet\"][[\"Date\",\"Prices\"]].copy();dataHizmet.set_index(\"Date\",inplace=True)\n",
    "    dataAlisveris = dataMonth(dataAlisveris)\n",
    "    dataYemek = dataMonth(dataYemek)\n",
    "    dataGiyim = dataMonth(dataGiyim)\n",
    "    dataFatura = dataMonth(dataFatura)\n",
    "    dataHizmet = dataMonth(dataHizmet)\n",
    "    dfAlisveris = dataAlisveris.rename(columns={'Date': 'ds','Prices': 'y'})\n",
    "    dfYemek = dataYemek.rename(columns={'Date': 'ds','Prices': 'y'})\n",
    "    dfGiyim = dataGiyim.rename(columns={'Date': 'ds','Prices': 'y'})\n",
    "    dfFatura = dataFatura.rename(columns={'Date': 'ds','Prices': 'y'})\n",
    "    dfHizmet = dataHizmet.rename(columns={'Date': 'ds','Prices': 'y'})\n",
    "    dfAlisveris = Fitting(dfAlisveris)\n",
    "    dfYemek = Fitting(dfYemek)\n",
    "    dfGiyim = Fitting(dfGiyim)\n",
    "    dfFatura = Fitting(dfFatura)\n",
    "    dfHizmet = Fitting(dfHizmet)\n",
    "    return dataYemek, dataGiyim, dataFatura, dataHizmet, dataAlisveris, dfYemek, dfGiyim, dfFatura, dfHizmet, dfAlisveris\n",
    "\n",
    "def Twitter(username=\"kuveytturk\"):\n",
    "    with open('turkce-stop-words.txt') as file:\n",
    "        stw = file.read()\n",
    "    stw = stw.split()\n",
    "    stw = [s.lower() for s in stw]\n",
    "    stop = stw\n",
    "\n",
    "    #Modellerin İçeri Alınması\n",
    "    kokbul1 = stemmer('turkish')\n",
    "    filename = 'model.sav'\n",
    "    filenamev2 = 'vectorizer.sav'\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    loaded_vectorizer = pickle.load(open(filenamev2, 'rb'))\n",
    "    def preprocessing(text):\n",
    "        text = text.lower()\n",
    "        # get rid of non-alphanumerical characters\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        # get rid of spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "            # Correct mistakes\n",
    "            # and do the stemming\n",
    "        return \" \".join([word for word in kokbul1.stemWords(text.split()) if word not in stop])\n",
    "\n",
    "    def predicting(x):\n",
    "        test_sample = []\n",
    "        for i in range(len(x)):\n",
    "            test_sample.append(preprocessing(x[i]))\n",
    "        sample = loaded_vectorizer.transform(test_sample).toarray()\n",
    "        result = loaded_model.predict(sample)\n",
    "        return result\n",
    "\n",
    "    def Graph(result):\n",
    "        labels = ['Olumsuz', 'Nötr', 'Olumlu']\n",
    "        sizes = [(result == 0).sum(), (result == 1).sum(), (result == 2).sum()]\n",
    "        colors = ['Red', 'gold', 'yellowgreen']\n",
    "        patches, texts = plt.pie(sizes, colors=colors, shadow=True,startangle=90)\n",
    "        plt.legend(patches, labels, loc=\"best\")\n",
    "        plt.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "    def GetTweets(username):\n",
    "        #Twitter API Settings\n",
    "        auth = tweepy.OAuthHandler(\"b31NqruIj0m3D6mzOk4glEfz7\",\"yAku57PMlQ9V6MVxUrrzkGxI4izrwGCzvI8Q5OwPwyFeLCR0oT\")\n",
    "        auth.set_access_token(\"352938901-hH3mCRnw7ir8acB7oFQwfsu9gaboZeu20Hbm2jWi\", \"t2vYixvZemUibVI95QuapcqwEUCITki7xWFK6DjLTvGce\")\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        #Get Tweets\n",
    "        tweets = []\n",
    "        fetched_tweets = api.user_timeline(screen_name = username, count = 100, include_rts = True)\n",
    "\n",
    "        for tweet in fetched_tweets:\n",
    "            tweets.append(preprocessing(tweet.text))\n",
    "\n",
    "        sentiment = {'olumsuz':0, 'notr':1, 'olumlu':2}\n",
    "        sentimentters = {0:'Olumsuz', 1:'Notr', 2:'Olumlu'}\n",
    "        inv_sentiment = {v:k for k, v in sentiment.items()}\n",
    "\n",
    "        result =  predicting(tweets)\n",
    "\n",
    "        sentimentters = {0:'Olumsuz', 1:'Notr', 2:'Olumlu'}\n",
    "        x,y,c = [],[],[]\n",
    "\n",
    "        x = list(pd.DataFrame(result)[0].map(sentimentters).value_counts().values)\n",
    "        y = list(pd.DataFrame(result)[0].map(sentimentters).value_counts().index)\n",
    "        c = pd.DataFrame(x,y,columns=[username]).T\n",
    "        return c\n",
    "    c = GetTweets(username)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025900288779450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcustomer = GetData(\"4025900288779450\")\n",
    "GetGroup(newcustomer,\"4025900288779450\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4025900418055430 - Class 3\n",
    "#4025900213283250 - Class 2\n",
    "#4025900288779450 - Class 0\n",
    "#4025900517881690 - Class 1\n",
    "\n",
    "#Limitler Bazında\n",
    "#Grup 0 Öğrenciler Çünkü Kredi Kartı Limitleri AŞIRI DÜŞÜK\n",
    "#Grup 3 Emekli-Esnaf Limitler Düşük - Orta\n",
    "#Grup 1 Beyaz-Altın Yakalılar Limitler Yüksek\n",
    "#Grup 2 Mavi Yakalılar Çünkü Limitler Orta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n",
      "INFO:fbprophet.forecaster:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 12.0.\n"
     ]
    }
   ],
   "source": [
    "dataYemek, dataGiyim, dataFatura, dataHizmet, dataAlisveris, dfYemek, dfGiyim, dfFatura, dfHizmet, dfAlisveris = TimeSeries(\"number2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ds': {17: Timestamp('2019-04-30 00:00:00'),\n",
       "  18: Timestamp('2019-05-31 00:00:00'),\n",
       "  19: Timestamp('2019-06-30 00:00:00')},\n",
       " 'yhat': {17: 634.6830408449445, 18: 616.3852823579942, 19: 598.6777741448167}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme = dfYemek.to_dict()\n",
    "deneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prices': {0: 1131,\n",
       "  1: 1143,\n",
       "  2: 332,\n",
       "  3: 1267,\n",
       "  4: 975,\n",
       "  5: 353,\n",
       "  6: 816,\n",
       "  7: 627,\n",
       "  8: 537,\n",
       "  9: 585,\n",
       "  10: 822,\n",
       "  11: 893,\n",
       "  12: 646,\n",
       "  13: 1222,\n",
       "  14: 580,\n",
       "  15: 1172,\n",
       "  16: 891},\n",
       " 'Date': {0: Timestamp('2017-11-30 00:00:00'),\n",
       "  1: Timestamp('2017-12-31 00:00:00'),\n",
       "  2: Timestamp('2018-01-31 00:00:00'),\n",
       "  3: Timestamp('2018-02-28 00:00:00'),\n",
       "  4: Timestamp('2018-03-31 00:00:00'),\n",
       "  5: Timestamp('2018-04-30 00:00:00'),\n",
       "  6: Timestamp('2018-05-31 00:00:00'),\n",
       "  7: Timestamp('2018-06-30 00:00:00'),\n",
       "  8: Timestamp('2018-07-31 00:00:00'),\n",
       "  9: Timestamp('2018-08-31 00:00:00'),\n",
       "  10: Timestamp('2018-09-30 00:00:00'),\n",
       "  11: Timestamp('2018-10-31 00:00:00'),\n",
       "  12: Timestamp('2018-11-30 00:00:00'),\n",
       "  13: Timestamp('2018-12-31 00:00:00'),\n",
       "  14: Timestamp('2019-01-31 00:00:00'),\n",
       "  15: Timestamp('2019-02-28 00:00:00'),\n",
       "  16: Timestamp('2019-03-31 00:00:00')}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alışveriş'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def EnCokHarcamaYapilanAlan(dataYemek,dataAlisveris, dataFatura, dataGiyim, dataHizmet):\n",
    "    analysisdf = pd.DataFrame({\"Yemek\":dataYemek.Prices.values[-1],\n",
    "                  \"Alışveriş\":dataAlisveris.Prices.values[-1],\n",
    "                  \"Fatura\":dataFatura.Prices.values[-1],\n",
    "                  \"Giyim\":dataGiyim.Prices.values[-1],\n",
    "                  \"Hizmet\":dataHizmet.Prices.values[-1]},index=[0]).iloc[0]\n",
    "    return analysisdf.index[list(analysisdf.values).index(analysisdf.values.max())]\n",
    "\n",
    "EnCokHarcamaYapilanAlan(dataYemek,dataAlisveris, dataFatura, dataGiyim, dataHizmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
